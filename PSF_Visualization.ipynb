{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSF_Visualization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rinnibhan/octopi-psf-visualization/blob/main/PSF_Visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cvICGKBSGi2"
      },
      "source": [
        "# PSF Visualization \n",
        "### Goal: \n",
        "  Acquire and visualize PSF function for objective lens on Octopi\n",
        "### Steps:\n",
        "1. Import images from GCS\n",
        "2. Identify bead locations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5C0-RtNSkAU"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1lvo1x-xumB"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')           # we mount the drive at /content/drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7sMJm9rO1lz"
      },
      "source": [
        "import numpy as np\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "import re\n",
        "from skimage import color\n",
        "from math import sqrt\n",
        "from skimage import data\n",
        "from skimage.feature import blob_log\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFcNRuj9OiDY"
      },
      "source": [
        "# remove default colab files\n",
        "!rm -rf sample_data\n",
        "!rm adc.json\n",
        "!mkdir psf_im\n",
        "%cd psf_im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHgGRJBLUmKD"
      },
      "source": [
        "## Set up GCS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77W5QbTX5klq"
      },
      "source": [
        "# global variables\n",
        "project_id = 'soe-octopi'\n",
        "bucket_name = 'octopi-malaria-data'\n",
        "\n",
        "# enter the name of the folder in GCS directly above the folders with the objective configurations' z-stacks\n",
        "# note: the folder set-up should be: \n",
        "# gs_folder_path > \"objective config folder\" > \"0\" > *z-stack images* and \"blobs\" > *PSF images*\n",
        "gs_folder_path_1 = 'gs://octopi-malaria-data/20210809_20x_beads/'\n",
        "gs_folder_path_2 = 'gs://octopi-malaria-data/20210310_objectives_characterizations_with_beads/*/'\n",
        "\n",
        "# accesses all z stack images\n",
        "gen_folder_path = gs_folder_path_2 + \"*/*\" \n",
        "\n",
        "# place to save random PSFs in drive, with the MIP visualization\n",
        "dr_save_path = '/content/drive/MyDrive/Sophomore/Research/Octopi/PSF Visualization'\n",
        "\n",
        "folder_paths_dict = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9LhUOqnWiDF"
      },
      "source": [
        "# set project\n",
        "def set_project(proj_id):\n",
        "  !gcloud config set project {proj_id}\n",
        "\n",
        "# list elements of folder in bucket\n",
        "def list_folder(f_path):\n",
        "  files = !gsutil ls \"{f_path}\"\n",
        "  return files\n",
        "\n",
        "# copy folder from bucket to colab; returns name of file saved locally\n",
        "def copy_single_file(f_path):\n",
        "  slashes = [m.start() for m in re.finditer(r\"/\",f_path)]\n",
        "  location = \"./\" + f_path[slashes[-3]+1:slashes[-2]] + f_path[slashes[-1]:] # name of path to file saved locally\n",
        "  folder_paths_dict[\"./\" + f_path[slashes[-3]+1:slashes[-2]]] = f_path[:slashes[-1]]\n",
        "  !gsutil -m cp -r \"{f_path}\" \"{location}\"\n",
        "  return location\n",
        "\n",
        "def copy_file_list(files):\n",
        "  # files: list of GCS paths to files to copy\n",
        "  local_files = []\n",
        "  for file in files: \n",
        "    location = copy_single_file(file) # saves each file locally\n",
        "    local_files.append(location)\n",
        "  local_files = np.asarray(local_files) # names of paths to files saved locally\n",
        "  return local_files\n",
        "\n",
        "# list fluorescence images in folder \n",
        "def find_fluorescence_images(f_path):\n",
        "  files = list_folder(f_path)\n",
        "  files = np.asarray(files)\n",
        "  find_fluorescence_mask = np.char.find(files, \"405\")\n",
        "\n",
        "  files = files[find_fluorescence_mask > 0]\n",
        "  return files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAppoGM1Hjvw"
      },
      "source": [
        "# copy all fluorescence images in all folders from gen_folder path\n",
        "files = find_fluorescence_images(gen_folder_path) # get list of files to copy; fluorescent images from each folder in bucket\n",
        "copy_file_list(files) # copy files locally; update dict of local file names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugppMHcwQGFA"
      },
      "source": [
        "## Find Maximum Intensity Projection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcCppn1KqeI9"
      },
      "source": [
        "Steps:\n",
        "1. Fn: get z-stack 3D HSV array from folder name\n",
        "2. Fn: get MIP from z-stack 3D HSV array\n",
        "3. Fn: get blob coordinates + radii from MIP\n",
        "4. Fn: given blob cross section and destination folder name, save image to GCS\n",
        "5. Fn: Given blob coordinates + radii and z-stack 3D HSV array + folder name, construct list of 2D arrays of blob cross sections (across all layers of stack); store plots of every blob in this list in a folder (blob_plots) within the folder; also add list to a dictionary (folder name : list)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3izEy7IrNF1"
      },
      "source": [
        "# find z-stack of images given folder name\n",
        "def find_hsv_z_stack(fold_name):\n",
        "  # fold_name: name of folder saved in psf_im with the stack of images\n",
        "  im_files_doubled = !ls {fold_name} # named as such because !ls saves files to list in pairs concatenated in 1 string\n",
        "  im_files_v = [] # concatenated stack of images (each array element = pixel \"value\", from HSV)\n",
        "  im_files = [] # list of image file names\n",
        "  for pair in im_files_doubled: # separate into actual list of files in folder\n",
        "    comp = pair.split(\"'\")\n",
        "    im_files.append(comp[1])\n",
        "    if len(comp) >= 4:\n",
        "      im_files.append(comp[3])\n",
        "  for im_path in im_files: # concatenate images into list\n",
        "    full_path = '/content/psf_im/' + fold_name[1:-1] + '/' + im_path\n",
        "    try:\n",
        "      img = Image.open(full_path) # open the image file\n",
        "      img.verify() # verify that it is, in fact an image\n",
        "    except (IOError, SyntaxError) as e:\n",
        "      print('Bad file:', full_path)\n",
        "      os.remove(full_path)\n",
        "      continue\n",
        "    im = imageio.imread(full_path)\n",
        "    im_hsv = color.rgb2hsv(im) # convert RGB image to HSV\n",
        "    im_v = im_hsv[:,:,2] # isolate V array\n",
        "    im_files_v.append(im_v) # add to list of V arrays for each image\n",
        "  im_z_stack = np.stack(im_files_v) # stack V arrays for all image\n",
        "  return im_z_stack\n",
        "\n",
        "# find rgb z-stack of images given folder name (ordered by img file name)\n",
        "def find_rgb_z_stack(fold_name):\n",
        "  # fold_name: name of folder saved in psf_im with the stack of images\n",
        "  im_files_doubled = !ls {fold_name} # named as such because !ls saves files to list in pairs concatenated in 1 string\n",
        "  im_files = [] # list of image file names\n",
        "  for pair in im_files_doubled: # separate into actual list of files in folder\n",
        "    comp = pair.split(\"'\")\n",
        "    im_files.append(comp[1])\n",
        "    if len(comp) >= 4:\n",
        "      im_files.append(comp[3])\n",
        "  im_files_v = [None] * len(im_files) # concatenated stack of images (each array element = pixel \"value\", from HSV)\n",
        "  for im_path in im_files: # concatenate images into list\n",
        "    im = imageio.imread('/content/psf_im/' + fold_name[1:-1] + '/' + im_path)\n",
        "    im_ind = im_path[4:im_path.find(\"Fl\")]\n",
        "    im_files_v[int(im_ind)] = im # add to list of V arrays for each image\n",
        "  im_z_stack = np.stack(im_files_v) # stack V arrays for all image\n",
        "  return im_z_stack\n",
        "\n",
        "# find max intensity projection given a z-stack of images\n",
        "def find_max_int_proj(im_z_stack):\n",
        "  return np.max(im_z_stack, axis=0)\n",
        "\n",
        "# find all max intensity projections for all imported folders + create dictionary:\n",
        "# returns dictionary of max intensity projections for all of the z-stacks of images (for each nested folder)\n",
        "def find_all_max_int_proj():\n",
        "  # make sure you're in top folder, which contains all nested folders of z-stacks\n",
        "  folders = !ls # get list of folders that were just saved\n",
        "  max_int_proj_dict = {}\n",
        "  for folder in folders: # go through folders\n",
        "    im_z_stack = find_hsv_z_stack(folder)\n",
        "    im_max_int = find_max_int_proj(im_z_stack) # create a max intensity projection for the stack of images in the folder\n",
        "    max_int_proj_dict[folder] = im_max_int\n",
        "  return max_int_proj_dict\n",
        "\n",
        "# display all MIPs saved in dictionary\n",
        "def disp_all_max_int_proj(max_int_proj_dict):\n",
        "  ims = list(max_int_proj_dict.values())\n",
        "  if len(max_int_proj_dict) > 1:   \n",
        "    # display all max intensity projections\n",
        "    f,ax=plt.subplots(1,len(max_int_proj_dict))\n",
        "    for i in range(len(max_int_proj_dict)):\n",
        "      im = ims[i]\n",
        "      ax[i].imshow(im)\n",
        "    plt.tight_layout()\n",
        "  else:\n",
        "    plt.imshow(ims[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKmiJ88HQJBk"
      },
      "source": [
        "## Blob detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKDbrtb-QwcS"
      },
      "source": [
        "# given z-stack, create 3D array with: \n",
        "# 0: x coordinates of blobs (from LoG blob detection)\n",
        "# 1: y coordinates of blobs\n",
        "# 2: radii of blobs\n",
        "def find_LoG_blobs(im_z_stack):\n",
        "  mip = find_max_int_proj(im_z_stack)\n",
        "  # find blobs\n",
        "  blobs_log = blob_log(mip, max_sigma=30, num_sigma=10, threshold=.1)\n",
        "  blobs_log[:, 2] = blobs_log[:, 2] * sqrt(2) # Compute radii in the 3rd column\n",
        "  np.swapaxes(blobs_log, 0, 1) # move x coord to first; y coord to second axis\n",
        "  return blobs_log\n",
        "\n",
        "# subset of np.array (3D, because RGB) given center index and side length\n",
        "def fixed_size_subset(arr, x, y, size):\n",
        "    x = int(x)\n",
        "    y = int(y)\n",
        "    o, r = np.divmod(size, 2)\n",
        "    l = (x-(o+r-1)).clip(0)\n",
        "    u = (y-(o+r-1)).clip(0)\n",
        "    arr_ = arr[l: x+o+1, u:y+o+1, :]\n",
        "    out = np.full((size, size, 3), 0, dtype=arr.dtype) # fill cut-off values with 0's\n",
        "    out[:arr_.shape[0], :arr_.shape[1], :] = arr_\n",
        "    return out\n",
        "    \n",
        "# return blob cross section given z-stack and x,y coordinates + crop size\n",
        "def find_blob_cross_section(im_z_stack, x, y, crop_s):\n",
        "  blob_slices = []\n",
        "  for i in range(im_z_stack.shape[0]):\n",
        "    im_rgb = im_z_stack[i]\n",
        "    blob_square = fixed_size_subset(im_rgb, x, y, crop_s)\n",
        "    blob_slice = blob_square[int(crop_s/2),:,:]\n",
        "    blob_slices.append(blob_slice)\n",
        "    stack = np.stack(blob_slices)\n",
        "  return stack\n",
        "\n",
        "# save images of a blob cross section given the cs and the destination folder path\n",
        "def save_blob_im(blob_cs, loc_file, dest_file):\n",
        "  im = Image.fromarray(blob_cs)\n",
        "  im.save(loc_file)\n",
        "  !gsutil cp '{loc_file}' '{dest_file}'\n",
        "  return\n",
        "\n",
        "# save images of every blob cross section in a z-stack; returns list of all blob cross sections \n",
        "def find_stack_blob_cross_sections(loc_fold, crop_s):\n",
        "  hsv_z_stack = find_hsv_z_stack(loc_fold)\n",
        "  rgb_z_stack = find_rgb_z_stack(loc_fold)\n",
        "  blobs_log = find_LoG_blobs(hsv_z_stack)\n",
        "  blob_cross_sections = []\n",
        "  new_fold = loc_fold[1:-1] + \"/blobs\"\n",
        "  print(new_fold + \" << new fold\")\n",
        "  !mkdir \"{new_fold}\"\n",
        "  for blob in blobs_log: # for every blob; identified in the mip image\n",
        "    x, y, r = blob\n",
        "    blob_cs = find_blob_cross_section(rgb_z_stack, x, y, crop_s) # find a 2D array of the cross section\n",
        "    blob_cross_sections.append(blob_cs) # add it to the list\n",
        "    # paths\n",
        "    loc_file = loc_fold[1:-1] + \"/blobs/\" + str(int(x)) + \"_\" + str(int(y)) + \".png\" # name of local file to save this blob CS image\n",
        "    dest_fold = folder_paths_dict[\"./\" + loc_fold[1:-1]] # name of bucket folder to save this blob CS image\n",
        "    dest_file = dest_fold + \"/blobs/\" + str(int(x)) + \"_\" + str(int(y)) + \".png\" # name of bucket file to save this blob CS image\n",
        "    print(loc_file, dest_file)\n",
        "    save_blob_im(blob_cs, loc_file, dest_file)\n",
        "  return blob_cross_sections\n",
        "\n",
        "# save images of every z-stack's blob CSs\n",
        "def find_all_stacks_blob_cross_sections(crop_s):\n",
        "  # make sure you're in top folder, which contains all nested folders of z-stacks\n",
        "  folders = !ls # get list of folders that were just saved\n",
        "  for folder in folders: # go through folders\n",
        "    find_stack_blob_cross_sections(folder, crop_s)\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8UtN7nFr3b0"
      },
      "source": [
        "# only if you want to save PSF visualizations to GCS\n",
        "find_all_stacks_blob_cross_sections(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYSVZd3IbRde"
      },
      "source": [
        "## Save Random PSF Images to Google Drive (slide deck)\n",
        "Saves 10 randomly selected PSF images from GCS to Google Drive for each objective lens z-stack folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3IBINUv-btU"
      },
      "source": [
        "# get dictionary of all MIPs\n",
        "mip_dict = find_all_max_int_proj()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnK0anBqfAPo"
      },
      "source": [
        "%cd '/content/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4vqGRz0kDqi"
      },
      "source": [
        "# saves a side-by-side of the PSF visualization for a bead, and an image of the MIP for that z-stack with the specific bead surrounded by a red box\n",
        "# also saves just the PSF visualization of the bead to gdr_save_path\n",
        "# gcs_blob_path: path to blob in GCS (\"gs://.../y_x.png\")\n",
        "# gdr_blob_path: path where blob is saved in Google Drive (\"/content/drive/.../y_x.png\")\n",
        "def save_blob_local_and_global(gcs_blob_path, gdr_blob_path, mip_dict, z_to_x_ratio):\n",
        "  # save PSF to Google Drive\n",
        "  !gsutil cp \"{gcs_blob_path}\" \"{gdr_blob_path}\"\n",
        "  # extract y and x coordinates\n",
        "  y_x_png = gdr_blob_path[gdr_blob_path.rfind('/')+1:]\n",
        "  y = y_x_png[:y_x_png.find('_')]\n",
        "  x = y_x_png[y_x_png.find('_')+1:y_x_png.find('.')]\n",
        "  y = int(y)\n",
        "  x = int(x)\n",
        "  print(str(y) + \",\" + str(x))\n",
        "  # get folder name (to get MIP)\n",
        "  fold = gcs_blob_path\n",
        "  for i in range(3):\n",
        "    fold = fold[:fold.rfind('/')]\n",
        "  fold = fold[fold.rfind('/')+1:]\n",
        "  fold = \"'\" + fold + \"'\"\n",
        "  # create red box around blob in the MIP image\n",
        "  mip_boxed = np.copy(mip_dict[fold])\n",
        "  mip_boxed = addBoundingBox(mip_boxed,x,y,25)\n",
        "  # get PSF of blob\n",
        "  im_s = mip_boxed.shape[0]\n",
        "  psf_im = imageio.imread(gdr_blob_path)\n",
        "  psf_im_width = psf_im.shape[1] # number of columns (width)\n",
        "  psf_im_height = psf_im.shape[0] * z_to_x_ratio # appropriate number of rows (height), based on x/z scaling factor\n",
        "  psf_im_height_up = int(im_s) # match number of rows\n",
        "  psf_im_width_up = int(im_s*(psf_im_width/psf_im_height))\n",
        "  psf_upscale_dim = (psf_im_width_up,psf_im_height_up)\n",
        "  psf_im_up = np.zeros((psf_im_height_up,psf_im_width_up,3))\n",
        "  for i in range(psf_im.shape[2]):\n",
        "    psf_im_up[:,:,i] = cv2.resize(psf_im[:,:,i],psf_upscale_dim,interpolation = cv2.INTER_NEAREST)\n",
        "  # construct final image\n",
        "  white_space = np.ones((mip_boxed.shape[0], int(mip_boxed.shape[0]/50), 3))\n",
        "  tot_im = np.hstack((mip_boxed, white_space, psf_im_up/255))\n",
        "  plt.imshow(tot_im)\n",
        "  plt.axis('off')\n",
        "  # plt.title('PSF from: ' + fold + ' at coordinates ' + str(x) + \",\" + str(y))\n",
        "  fig_path = gdr_blob_path[:gdr_blob_path.rfind('/')+1] + str(y) + \"_\" + str(x) + \"_psf_vis.png\"\n",
        "  plt.savefig(fig_path, bbox_inches='tight', dpi=1000)\n",
        "  plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59h5YgmrHlns"
      },
      "source": [
        "def addBoundingBox(I,x,y,r,extension=2): # thickness is 2\n",
        "  if len(I.shape) == 2:\n",
        "    ny, nx = I.shape\n",
        "    I = np.dstack([I, I, I])\n",
        "  else:\n",
        "    ny, nx, nc = I.shape\n",
        "  x_min = max(x - r - extension,0)\n",
        "  y_min = max(y - r - extension,0)\n",
        "  x_max = min(x + r + extension,nx-1)\n",
        "  y_max = min(y + r + extension,ny-1)\n",
        "  I[y_min-3:y_min+3,x_min:x_max+1,:] = [1, 0, 0]\n",
        "  I[y_max-3:y_max+3,x_min:x_max+1,:] = [1, 0, 0]\n",
        "  I[y_min:y_max+1,x_min-3:x_min+3,:] = [1, 0, 0]\n",
        "  I[y_min:y_max+1,x_max-3:x_max+3,:] = [1, 0, 0]\n",
        "  return I"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOLZIZr0v6pY"
      },
      "source": [
        "# save random PSF visualizations (blobs) from each objectives folder within the parent folder to the drive folder\n",
        "# gs_folder_path: path to the parent folder in GCS which is directly above the folders for each objective lens configuration (each objective folder should contain the z-stack and blobs folder, created above)\n",
        "# dr_save_path: path in Google Drive to which the randomly selected blobs will be saved\n",
        "# num_blobs: number of blobs to select from each folder of blobs \n",
        "def save_rand_blobs(gs_folder_path, dr_save_path, num_blobs=10):\n",
        "  obj_folds = !gsutil ls \"{gs_folder_path}\"\n",
        "  obj_folds = [obj_folds[9]]\n",
        "  for obj_fold in obj_folds: # for each objective folder (containing a z-stack for a given objective and its blobs folder)\n",
        "    obj_fold_dr = obj_fold[:-1]\n",
        "    obj_fold_dr = obj_fold_dr[obj_fold_dr.rfind('/')+1:]\n",
        "    # # create equivalent folder in google drive if necessary\n",
        "    # if not os.path.exists(dr_save_path + '/' + obj_fold_dr + '/0/blobs'): # create folder in drive that blobs will be saved to\n",
        "    #   os.mkdir(dr_save_path + '/' + obj_fold_dr)\n",
        "    #   os.mkdir(dr_save_path + '/' + obj_fold_dr + '/0/')\n",
        "    #   os.mkdir(dr_save_path + '/' + obj_fold_dr + '/0/blobs/')\n",
        "    #   print(\"made directory: \" + dr_save_path + '/' + obj_fold_dr + '/0/blobs/')\n",
        "    blobs = !gsutil ls \"{obj_fold + \"0/blobs\"}\"\n",
        "    # select num_blobs blobs to save\n",
        "    blobs_to_save = random.sample(blobs, num_blobs)\n",
        "    for gcs_blob_path in blobs_to_save:\n",
        "      bp = gcs_blob_path\n",
        "      for i in range(4):\n",
        "        bp = bp[bp.find('/')+1:]\n",
        "      gdr_blob_path = dr_save_path + \"/\" + bp\n",
        "      save_blob_local_and_global(gcs_blob_path,gdr_blob_path,mip_dict,(3/0.1665))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkWSZHusPnAQ"
      },
      "source": [
        "x = !gsutil ls \"{gs_folder_path_2}\"\n",
        "x[9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIaPc1OllAWG"
      },
      "source": [
        "save_rand_blobs(gs_folder_path_2, dr_save_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}